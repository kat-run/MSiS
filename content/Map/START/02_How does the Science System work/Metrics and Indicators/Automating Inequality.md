**Node**

**Area (colour)**

[üìì**Mini-Case-Studies](https://lean-sphynx-49b.notion.site/Mini-Case-Studies-a525a9ad87de4bca9a100f115821640b?pvs=21)

**Tags**

[üè∑Ô∏èCapitalism](https://lean-sphynx-49b.notion.site/Capitalism-92ab400b37bd411da460073c2ee4fb05?pvs=21) [üè∑Ô∏èTechnology](https://lean-sphynx-49b.notion.site/Technology-d848dea8e396403f946fa485dc5cf19e?pvs=21) [üè∑Ô∏èPolitics](https://lean-sphynx-49b.notion.site/Politics-9e5263cc233a464398a41fc45c125005?pvs=21)

**Links**

[üè∑Ô∏èTechnology](https://lean-sphynx-49b.notion.site/Technology-d848dea8e396403f946fa485dc5cf19e?pvs=21)

**Literature**

[Eubanks, 2019](https://lean-sphynx-49b.notion.site/Eubanks-2019-aa8a7640506d4f5a833cf708b1446041?pvs=21)

**Abstract/Summary (perplexity AI)**

In her book "Automating Inequality: How High-Tech Tools Profile, Police, and Punish the Poor", Virginia Eubanks systematically investigates the impacts of data mining, policy algorithms, and predictive risk models on poor and working-class people in America[1][3]. Through three case studies focused on welfare, homelessness, and child protection services, Eubanks argues that automated decision-making systems are the latest in a long history of measures that profile, police and punish the poor[2][4].

In Indiana, a new automated welfare system led to over 1 million denied applications for healthcare, food stamps and cash benefits in just 3 years, as any mistake was interpreted as "failure to cooperate"[1][2]. In Los Angeles, an algorithm prioritizes the homeless for housing resources based on a vulnerability score calculated from invasive personal data[2][4]. And in Allegheny County, Pennsylvania, a child welfare algorithm predicts which children might be future abuse victims, based on statistical proxies rather than actual risk factors[2][4].

Eubanks argues these "digital poorhouses" of the 21st century can act more quickly, at greater scale, and with more hidden impacts than historical poorhouses[2][3]. She shows how automated systems disproportionately target and punish the poor, especially people of color, and embed existing racial and class biases[2][3][4]. The book is a powerful expos√© of how data-driven tools are being used to surveil, profile and punish marginalized communities[3][5].

Citations:  
[1]  
[https://us.macmillan.com/books/9781250074317/automatinginequality](https://us.macmillan.com/books/9781250074317/automatinginequality)  
[2]  
[https://blogs.lse.ac.uk/lsereviewofbooks/2018/07/02/book-review-automating-inequality-how-high-tech-tools-profile-police-and-punish-the-poor-by-virginia-eubanks/](https://blogs.lse.ac.uk/lsereviewofbooks/2018/07/02/book-review-automating-inequality-how-high-tech-tools-profile-police-and-punish-the-poor-by-virginia-eubanks/)  
[3]  
[https://virginia-eubanks.com/automating-inequality/](https://virginia-eubanks.com/automating-inequality/)  
[4]  
[https://www.morgan-klaus.com/readings/automating-inequality.html](https://www.morgan-klaus.com/readings/automating-inequality.html)  
[5]  
[https://www.socialworker.com/feature-articles/reviews-commentary/book-review-automating-inequality-how-high-tech-tools-profile-police-punish-poor/](https://www.socialworker.com/feature-articles/reviews-commentary/book-review-automating-inequality-how-high-tech-tools-profile-police-punish-poor/)