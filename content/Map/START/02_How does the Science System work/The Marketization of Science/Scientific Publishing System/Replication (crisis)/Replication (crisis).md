**Node**

**Area (colour)**

[üéì**Disciplines](https://lean-sphynx-49b.notion.site/Disciplines-72ba770b397c4f34aed13a10d8d0cc3e?pvs=21)

**Tags**

[üè∑Ô∏èPublishing](https://lean-sphynx-49b.notion.site/Publishing-8d3c55fe5c894b3b9c1ebb666ebe341d?pvs=21) üååCosmos: Accountability




**Links**

[[How Does Science Work]] [[Sokal Affair and Sokal Squared]] [[The strain on scientific publishing]]

**Literature**

[Schmidt, 2009](https://lean-sphynx-49b.notion.site/Schmidt-2009-0fa88a0e8cb9410fbb2409cfcd087266?pvs=21) [Baker, 2016](https://lean-sphynx-49b.notion.site/Baker-2016-a15a11de2ebe4688a8e39e025e9b8753?pvs=21) [Begley & Ellis, 2012](https://lean-sphynx-49b.notion.site/Begley-Ellis-2012-f5749900d5694f0d9639e04ecafc086a?pvs=21) [Simmons et al., 2011](https://lean-sphynx-49b.notion.site/Simmons-et-al-2011-4ee25706091944108af80ad69eb10286?pvs=21) [Pashler & Harris, 2012](https://lean-sphynx-49b.notion.site/Pashler-Harris-2012-107b0c0bbdde4e0a94fa82c540abf4d6?pvs=21) [Romero, 2019](https://lean-sphynx-49b.notion.site/Romero-2019-ada3c2e05fed4386922317e34f618364?pvs=21) [Ware & Munaf√≤, 2015](https://lean-sphynx-49b.notion.site/Ware-Munaf-2015-ed37909bebd1448fa901c63491d6aa38?pvs=21) [Lehrer, 2010](https://lean-sphynx-49b.notion.site/Lehrer-2010-345e271aef9548b9a6a6284d6300931b?pvs=21) [Aschwanden, 2015](https://lean-sphynx-49b.notion.site/Aschwanden-2015-d07901319fc44ff2820defe3de52e1cc?pvs=21) [Pashler & Harris, 2012](https://lean-sphynx-49b.notion.site/Pashler-Harris-2012-107b0c0bbdde4e0a94fa82c540abf4d6?pvs=21) [Ioannidis, 2005](https://lean-sphynx-49b.notion.site/Ioannidis-2005-d6b4997942e94f7c83c11fa708a18b45?pvs=21) [Chartier et al., 2018](https://lean-sphynx-49b.notion.site/Chartier-et-al-2018-cbe2a022aa2644e9b8d4336866154552?pvs=21)

**Abstract/Summary**

> _Replication is one of the central issues in any empirical science. To confirm results or hypotheses by a repetition procedure is at the basis of any scientific conception. A replication experiment to demonstrate that the same findings can be obtained in any other place by any other researcher is conceived as an operationalization of objectivity. It is the proof that the experiment reflects knowledge that can be separated from the specific circumstances (such as time, place, or persons) under which it was gained._

[Schmidt, 2009](https://lean-sphynx-49b.notion.site/Schmidt-2009-0fa88a0e8cb9410fbb2409cfcd087266?pvs=21) p.90

Reproducing published results is a cornerstone of the scientific method. However, with the steep rise in scientific publications, the practice of reproducing results found in the scientific literature has firstly become less frequent and secondly, published results often simply cannot be reproduced in different labs. A 2016 survey by the journal _Nature_ found that ‚Äúmore than 70% of researchers have tried and failed to reproduce another scientist's experiments, and more than half have failed to reproduce their own experiments.‚Äù [Baker, 2016](https://lean-sphynx-49b.notion.site/Baker-2016-a15a11de2ebe4688a8e39e025e9b8753?pvs=21). Reproducibility issues are prevalent in all applied disciplines, but differ in scale. While disciplines like physics and chemistry seem to be less affected, in others like **psychology** and **cancer research** most results have been found to be non-reproducible (although to varying degrees) [Begley & Ellis, 2012](https://lean-sphynx-49b.notion.site/Begley-Ellis-2012-f5749900d5694f0d9639e04ecafc086a?pvs=21) [Simmons et al., 2011](https://lean-sphynx-49b.notion.site/Simmons-et-al-2011-4ee25706091944108af80ad69eb10286?pvs=21).

![[/Untitled 13.png|Untitled 13.png]]

Taken from [Baker, 2016](https://lean-sphynx-49b.notion.site/Baker-2016-a15a11de2ebe4688a8e39e025e9b8753?pvs=21)

Especially in psychology, the replication crisis gained wider public attention (see for instance [Lehrer, 2010](https://lean-sphynx-49b.notion.site/Lehrer-2010-345e271aef9548b9a6a6284d6300931b?pvs=21) or [Aschwanden, 2015](https://lean-sphynx-49b.notion.site/Aschwanden-2015-d07901319fc44ff2820defe3de52e1cc?pvs=21)) and raised fundamental questions about how contemporary research and publishing needs to be restructured ([Pashler & Harris, 2012](https://lean-sphynx-49b.notion.site/Pashler-Harris-2012-107b0c0bbdde4e0a94fa82c540abf4d6?pvs=21)).

The problem has many layers, but it is important to note that most failed replications are not due to fraudulent data of the original source. Instead, chance does play a major role, even though the scientific method tries to account for this. Papers can have different methodological flaws which might not be caught in the peer-review process. Some of these empirical issues are shortcomings of experimental models like cell lines or mouse strains ([Begley & Ellis, 2012](https://lean-sphynx-49b.notion.site/Begley-Ellis-2012-f5749900d5694f0d9639e04ecafc086a?pvs=21)), as well as statistical errors, flaws ([Ioannidis, 2005](https://lean-sphynx-49b.notion.site/Ioannidis-2005-d6b4997942e94f7c83c11fa708a18b45?pvs=21)) or practices like significance chasing a.k.a. ‚Äúp-value‚Äù hacking ([Ware & Munaf√≤, 2015](https://lean-sphynx-49b.notion.site/Ware-Munaf-2015-ed37909bebd1448fa901c63491d6aa38?pvs=21) [Simmons et al., 2011](https://lean-sphynx-49b.notion.site/Simmons-et-al-2011-4ee25706091944108af80ad69eb10286?pvs=21)). But also the [[Scientific Publishing System]] itself is contributing to the problem. Contradicting or inconclusive results of replications hardly get published as journals favor novelty ([Pashler & Harris, 2012](https://lean-sphynx-49b.notion.site/Pashler-Harris-2012-107b0c0bbdde4e0a94fa82c540abf4d6?pvs=21)); especially early-career researchers therefore often refrain from reporting negative results that they might encounter in their research.

Many measures have been proposed to compete against the replication crisis in different disciplines and on several levels of the publishing process. I list some of these below.

### Measures against the replication crisis

- Metascience: The study of science with scientific methods. For instance [StatCheck](https://michelenuijten.shinyapps.io/statcheck-web/) is a software that detects statistical flaws in psychology research papers. Although the program itself still has its flaws, it contributed finding many faulty papers in the discipline. [Baker, 2016](https://lean-sphynx-49b.notion.site/Baker-2016-be45417e53d740728c4c39fcbe72e068?pvs=21)
- A better description of methodology in research papers, a better description of statistical analysis methods and a better availability of raw data, for instance in the establishment of online databases for methods like Nature Genetics‚Äô [Online Methods](https://lean-sphynx-49b.notion.site/Pashler-Harris-2012-107b0c0bbdde4e0a94fa82c540abf4d6?pvs=21).
- Changes to the peer-review and submission process like [pre-registration](https://www.psychologicalscience.org/publications/replication) of studies or results-blind peer review ([Chartier et al., 2018](https://lean-sphynx-49b.notion.site/Chartier-et-al-2018-cbe2a022aa2644e9b8d4336866154552?pvs=21)) in which the study is reviewed (and accepted) by a journal before the experiments are carried out and published whether the hypothesis is confirmed or not.
- Better tools for tracking replications (metadata search)
- Changes in statistical analyses (for instance, less reliance on a fixed p-value of 0.05 for statements of significance and the use of other models to test significance, for instance Bayesian inference [Romero, 2019](https://lean-sphynx-49b.notion.site/Romero-2019-ada3c2e05fed4386922317e34f618364?pvs=21)
- Changes in the incentives to replicate scientific papers, like additional funding (has been done for instance by the main Dutch science funding agency), or encouraging Master students to work on replications in their theses.
- Broader changes in the way we publish and do science. Such as changes in the competitive nature of science and encouraging collaboration, rather than competition.